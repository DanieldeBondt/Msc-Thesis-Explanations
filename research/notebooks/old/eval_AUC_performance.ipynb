{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import standard modules for data handling and visualization\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "## import model specific modules\n",
    "import cplex as cp\n",
    "import slim_python as slim\n",
    "import shap\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\Documents\\StageDaniel\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 2] Het systeem kan het opgegeven bestand niet vinden: 'StageDaniel'\n",
      "C:\\Users\\danie\\Documents\\StageDaniel\n"
     ]
    }
   ],
   "source": [
    "cd StageDaniel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# haberman and breastcancer gives large slim values\n",
    "# mushroom and bankruptcy, spambase gives large ebm values \n",
    "# mushroom creates high sparsity for all models except EBM\n",
    "\n",
    "dataset = 'adult'\n",
    "def load_models(name):\n",
    "    with open('results/models/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "models = load_models(dataset+'_models')\n",
    "data = load_models(dataset+'_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+-------------------+-----------+\n",
      "| PREDICT O IF SCORE >= -1      |                   |           |\n",
      "| ============================= | ================= | ========= |\n",
      "| Married                       |          2 points |   + ..... |\n",
      "| AnyCapitalGains               |          2 points |   + ..... |\n",
      "| Age_22_to_29                  |         -2 points |   + ..... |\n",
      "| HSDiploma                     |         -2 points |   + ..... |\n",
      "| WorkHrsPerWeek_lt_40          |         -2 points |   + ..... |\n",
      "| NoHS                          |         -4 points |   + ..... |\n",
      "| ============================= | ================= | ========= |\n",
      "| ADD POINTS FROM ROWS 1 to 6   |             SCORE |   = ..... |\n",
      "+-------------------------------+-------------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "print(models[0][1]['string_model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def extract_results(results, X):\n",
    "    # Extract specific models from the results\n",
    "\n",
    "    slim_results = results[0][1]\n",
    "\n",
    "    rho = slim_results['rho']\n",
    "    slim_predictions = pred_slim(X,rho)\n",
    "\n",
    "    ebm = results[1]\n",
    "\n",
    "    XGboost = results[2]\n",
    "    explainer = shap.TreeExplainer(XGboost)\n",
    "    shap_values = explainer.shap_values(X)\n",
    "\n",
    "    logit = results[3]\n",
    "    \n",
    "    return rho, slim_predictions, ebm, explainer, shap_values, logit\n",
    "\n",
    "## Simple function for getting predictions for a SLIM scoring system\n",
    "def pred_slim(X, rho):\n",
    "    return (X.dot(rho[1:])+rho[0]>=0)*1\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def scale_sigmoid(x):\n",
    "    x_max = np.maximum(x.max(), np.abs(x.min()))\n",
    "    x = x/(x_max/5)\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def force_plot(explanations, model, X, pred_idx=0, link='identity'):\n",
    "    return shap.force_plot(explanations.loc[model][0], explanations.loc[model][1:-1].values, X.iloc[pred_idx,:], link=link)\n",
    "\n",
    "def auc(y, y_pred):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y, y_pred)\n",
    "    return metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_measures(data, models):\n",
    "    train_aucs = []\n",
    "    test_aucs = []\n",
    "    \n",
    "    X_train = data['X_train']\n",
    "    X_test = data['X_test']\n",
    "    y_train = data['y_train']\n",
    "    y_test = data['y_test']\n",
    "    \n",
    "    slim_results = models[0][1]\n",
    "    rho = slim_results['rho']\n",
    "    train_pred = scale_sigmoid(X_train.dot(rho[1:])+rho[0])\n",
    "    test_pred = sigmoid(X_test.dot(rho[1:])+rho[0])\n",
    "    train_aucs.append(auc(y_train,train_pred))\n",
    "    test_aucs.append(auc(y_test,test_pred))\n",
    "    \n",
    "    ebm = models[1]\n",
    "    train_pred = ebm.predict_proba(X_train)\n",
    "    test_pred = ebm.predict_proba(X_test)\n",
    "    train_aucs.append(auc(y_train,train_pred[:,1]))\n",
    "    test_aucs.append(auc(y_test,test_pred[:,1]))\n",
    "    \n",
    "    XGBoost = models[2]\n",
    "    train_pred = XGBoost.predict_proba(X_train)\n",
    "    test_pred = XGBoost.predict_proba(X_test)\n",
    "    train_aucs.append(auc(y_train,train_pred[:,1]))\n",
    "    test_aucs.append(auc(y_test,test_pred[:,1]))\n",
    "    \n",
    "    logit = models[3]\n",
    "    train_pred = logit.predict_proba(X_train)\n",
    "    test_pred = logit.predict_proba(X_test)\n",
    "    train_aucs.append(auc(y_train,train_pred[:,1]))\n",
    "    test_aucs.append(auc(y_test,test_pred[:,1]))\n",
    "\n",
    "    return pd.DataFrame([train_aucs, test_aucs], ['train', 'test'], ['slim', 'ebm', 'shap', 'logit'])\n",
    " \n",
    "    \n",
    "    \n",
    "# performance_measures(data, models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slim</th>\n",
       "      <th>ebm</th>\n",
       "      <th>shap</th>\n",
       "      <th>logit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>train</td>\n",
       "      <td>0.853272</td>\n",
       "      <td>0.891617</td>\n",
       "      <td>0.905032</td>\n",
       "      <td>0.891815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>test</td>\n",
       "      <td>0.851983</td>\n",
       "      <td>0.888937</td>\n",
       "      <td>0.893649</td>\n",
       "      <td>0.889084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           slim       ebm      shap     logit\n",
       "train  0.853272  0.891617  0.905032  0.891815\n",
       "test   0.851983  0.888937  0.893649  0.889084"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = ['bankruptcy','haberman', 'breastcancer', 'mammo', 'spambase', 'mushroom', 'adult']\n",
    "performances = []\n",
    "\n",
    "for dataname in names:\n",
    "    models = load_models(dataname+'_models_3600')\n",
    "    data = load_models(dataname+'_data_3600')\n",
    "    performance = performance_measures(data, models)\n",
    "    performances.append(performance)\n",
    "performances[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>validation</th>\n",
       "      <th>slim</th>\n",
       "      <th>ebm</th>\n",
       "      <th>shap</th>\n",
       "      <th>logit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>bankruptcy</td>\n",
       "      <td>train</td>\n",
       "      <td>0.993268</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>bankruptcy</td>\n",
       "      <td>test</td>\n",
       "      <td>0.993432</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>haberman</td>\n",
       "      <td>train</td>\n",
       "      <td>0.727394</td>\n",
       "      <td>0.828647</td>\n",
       "      <td>0.940302</td>\n",
       "      <td>0.742876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>haberman</td>\n",
       "      <td>test</td>\n",
       "      <td>0.604324</td>\n",
       "      <td>0.654054</td>\n",
       "      <td>0.603784</td>\n",
       "      <td>0.634595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>breastcancer</td>\n",
       "      <td>train</td>\n",
       "      <td>0.992634</td>\n",
       "      <td>0.999526</td>\n",
       "      <td>0.999837</td>\n",
       "      <td>0.996102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>breastcancer</td>\n",
       "      <td>test</td>\n",
       "      <td>0.992989</td>\n",
       "      <td>0.995172</td>\n",
       "      <td>0.995632</td>\n",
       "      <td>0.995172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>mammo</td>\n",
       "      <td>train</td>\n",
       "      <td>0.852860</td>\n",
       "      <td>0.857497</td>\n",
       "      <td>0.873702</td>\n",
       "      <td>0.856773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>mammo</td>\n",
       "      <td>test</td>\n",
       "      <td>0.851398</td>\n",
       "      <td>0.858925</td>\n",
       "      <td>0.850430</td>\n",
       "      <td>0.862957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>spambase</td>\n",
       "      <td>train</td>\n",
       "      <td>0.963674</td>\n",
       "      <td>0.990104</td>\n",
       "      <td>0.999495</td>\n",
       "      <td>0.977906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>spambase</td>\n",
       "      <td>test</td>\n",
       "      <td>0.957164</td>\n",
       "      <td>0.968050</td>\n",
       "      <td>0.989047</td>\n",
       "      <td>0.968251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>mushroom</td>\n",
       "      <td>train</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>mushroom</td>\n",
       "      <td>test</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>adult</td>\n",
       "      <td>train</td>\n",
       "      <td>0.853272</td>\n",
       "      <td>0.891617</td>\n",
       "      <td>0.905032</td>\n",
       "      <td>0.891815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>adult</td>\n",
       "      <td>test</td>\n",
       "      <td>0.851983</td>\n",
       "      <td>0.888937</td>\n",
       "      <td>0.893649</td>\n",
       "      <td>0.889084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         dataset validation      slim       ebm      shap     logit\n",
       "0     bankruptcy      train  0.993268  1.000000  1.000000  1.000000\n",
       "1     bankruptcy       test  0.993432  1.000000  1.000000  1.000000\n",
       "2       haberman      train  0.727394  0.828647  0.940302  0.742876\n",
       "3       haberman       test  0.604324  0.654054  0.603784  0.634595\n",
       "4   breastcancer      train  0.992634  0.999526  0.999837  0.996102\n",
       "5   breastcancer       test  0.992989  0.995172  0.995632  0.995172\n",
       "6          mammo      train  0.852860  0.857497  0.873702  0.856773\n",
       "7          mammo       test  0.851398  0.858925  0.850430  0.862957\n",
       "8       spambase      train  0.963674  0.990104  0.999495  0.977906\n",
       "9       spambase       test  0.957164  0.968050  0.989047  0.968251\n",
       "10      mushroom      train  1.000000  1.000000  1.000000  1.000000\n",
       "11      mushroom       test  1.000000  1.000000  1.000000  1.000000\n",
       "12         adult      train  0.853272  0.891617  0.905032  0.891815\n",
       "13         adult       test  0.851983  0.888937  0.893649  0.889084"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# corrs_df = pd.concat(corrs, keys = names)\n",
    "performance_df = pd.concat(performances, keys= names)\n",
    "performance_df.index.names = ['dataset', 'validation']\n",
    "performance_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrr}\n",
      "\\toprule\n",
      "{} & \\multicolumn{8}{l}{0} \\\\\n",
      "validation & \\multicolumn{4}{l}{test} & \\multicolumn{4}{l}{train} \\\\\n",
      "model &    ebm &  logit &   shap &   slim &    ebm &  logit &   shap &   slim \\\\\n",
      "dataset      &        &        &        &        &        &        &        &        \\\\\n",
      "\\midrule\n",
      "bankruptcy   &  1.000 &  1.000 &  1.000 &  0.993 &  1.000 &  1.000 &  1.000 &  0.993 \\\\\n",
      "haberman     &  0.654 &  0.635 &  0.604 &  0.604 &  0.829 &  0.743 &  0.940 &  0.727 \\\\\n",
      "breastcancer &  0.995 &  0.995 &  0.996 &  0.993 &  1.000 &  0.996 &  1.000 &  0.993 \\\\\n",
      "mammo        &  0.859 &  0.863 &  0.850 &  0.851 &  0.857 &  0.857 &  0.874 &  0.853 \\\\\n",
      "spambase     &  0.968 &  0.968 &  0.989 &  0.957 &  0.990 &  0.978 &  0.999 &  0.964 \\\\\n",
      "mushroom     &  1.000 &  1.000 &  1.000 &  1.000 &  1.000 &  1.000 &  1.000 &  1.000 \\\\\n",
      "adult        &  0.889 &  0.889 &  0.894 &  0.852 &  0.892 &  0.892 &  0.905 &  0.853 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stack = performance_df.stack()\n",
    "stack.index.names = ['dataset', 'validation', 'model']\n",
    "pivot = pd.pivot_table(pd.DataFrame(stack), index='dataset', columns = ['validation', 'model'])\n",
    "print(pivot.round(3).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(MultiIndex([( 'test',   'ebm'),\n",
       "             ('train',   'ebm'),\n",
       "             ( 'test', 'logit'),\n",
       "             ('train', 'logit'),\n",
       "             ( 'test',  'shap'),\n",
       "             ('train',  'shap'),\n",
       "             ( 'test',  'slim'),\n",
       "             ('train',  'slim')],\n",
       "            names=['validation', 'model']),\n",
       " array([0, 4, 1, 5, 2, 6, 3, 7], dtype=int64))"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pivot.columns = pivot.columns.droplevel(0)\n",
    "# pivot.columns.sortlevel(0)\n",
    "pivot.columns.sortlevel(1, ('train','slim'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2958.,    0.,    0.,  406.,    0.,    0., 1347.,    0.,    0.,\n",
       "        1788.]),\n",
       " array([-5., -4., -3., -2., -1.,  0.,  1.,  2.,  3.,  4.,  5.]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rho = models[0][1]['rho']\n",
    "x = X_train.dot(rho[1:])+rho[0]\n",
    "x_max = np.maximum(x.max(), np.abs(x.min()))\n",
    "x = x/(x_max/5)\n",
    "1/(1 + np.exp(-x))\n",
    "# np.abs(x.min()\n",
    "plt.hist(x.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
