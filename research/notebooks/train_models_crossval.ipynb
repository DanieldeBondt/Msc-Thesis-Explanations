{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for training different interpretabiliy models on cross validated train and test data#\n",
    " - Supersparse Linear Integer Model\n",
    " - Explainable Boostig Machine\n",
    " - XGBoost with SHAP explanations\n",
    " \n",
    " _DaniÃ«l de Bondt - Viqtor Davis NL_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import standard modules for data handling and visualization\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "## import model specific modules\n",
    "import cplex as cp\n",
    "import slim_python as slim\n",
    "import shap\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "## import additional functionalities\n",
    "from interpret import show\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, roc_auc_score, zero_one_loss, accuracy_score\n",
    "from sklearn import metrics\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## SLIM requires the data in a specific non dataframe format, this code prepares that\n",
    "def prep_data(X_train, y_train, X_test, y_test):\n",
    "    # requirements for slim data file\n",
    "    # - outcome variable in first column\n",
    "    # - outcome variable values should be [-1, 1] or [0, 1]\n",
    "    # - first row contains names for the outcome variable + input variables\n",
    "    # - no empty cells\n",
    "    \n",
    "    N_train = X_train.values.shape[0]\n",
    "    N_test = X_test.values.shape[0]\n",
    "\n",
    "    # setup Y vector and Y_name\n",
    "    y_name = y_test.name\n",
    "    y_train_slim = y_train.copy().values.reshape(len(y_train),1)\n",
    "    y_train_slim[y_train_slim == 0] = -1\n",
    "    y_test_slim = y_test.copy().values.reshape(len(y_test),1)\n",
    "    y_test_slim[y_test_slim == 0] = -1\n",
    "\n",
    "    # setup X and X_names\n",
    "    X_names = list(X_train.columns.values)\n",
    "    X_train_slim = X_train.values\n",
    "    X_test_slim = X_test.values\n",
    "    \n",
    "\n",
    "    # insert a column of ones to X for the intercept\n",
    "    X_train_slim = np.insert(arr = X_train_slim, obj = 0, values = np.ones(N_train), axis = 1)\n",
    "    X_test_slim = np.insert(arr = X_test_slim, obj = 0, values = np.ones(N_test), axis = 1)\n",
    "    X_names.insert(0, '(Intercept)')\n",
    "\n",
    "    # run sanity checks\n",
    "    slim.check_data(X = X_train_slim, Y = y_train_slim, X_names = X_names)      \n",
    "    \n",
    "    return (X_train_slim, X_test_slim, y_train_slim, y_test_slim, X_names, y_name)\n",
    "\n",
    "## Simple function for getting predictions for a SLIM scoring system\n",
    "def pred_slim(X, rho):\n",
    "    return (X.dot(rho[1:])+rho[0]>=0)*1\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def scale_sigmoid(x):\n",
    "    x_max = np.maximum(x.max(), np.abs(x.min()))\n",
    "    x = x/(x_max/100)\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def auc(y, y_pred):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y, y_pred)\n",
    "    return metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_slim(X, X_names, Y, y_name, params={}, timelimit=600.0, silent=True, imbalanced=False):\n",
    "    #### TRAIN SCORING SYSTEM USING SLIM ####\n",
    "    # setup SLIM coefficient set\n",
    "    coef_constraints = slim.SLIMCoefficientConstraints(variable_names = X_names, ub = 5, lb = -5)\n",
    "\n",
    "    scores_at_ub = (Y * X) * coef_constraints.ub\n",
    "    scores_at_lb = (Y * X) * coef_constraints.lb\n",
    "    non_intercept_ind = np.array([n != '(Intercept)' for n in X_names])\n",
    "    scores_at_ub = scores_at_ub[:, non_intercept_ind]\n",
    "    scores_at_lb = scores_at_lb[:, non_intercept_ind]\n",
    "    max_scores = np.fmax(scores_at_ub, scores_at_lb)\n",
    "    min_scores = np.fmin(scores_at_ub, scores_at_lb)\n",
    "    max_scores = np.sum(max_scores, 1)\n",
    "    min_scores = np.sum(min_scores, 1)\n",
    "\n",
    "    intercept_ub = -min(min_scores) + 1\n",
    "    intercept_lb = -max(max_scores) + 1\n",
    "    coef_constraints.set_field('ub', '(Intercept)', intercept_ub)\n",
    "    coef_constraints.set_field('lb', '(Intercept)', intercept_lb)\n",
    "\n",
    "    if imbalanced:\n",
    "        w_pos = 1.905\n",
    "        w_neg = 0.095\n",
    "    else:\n",
    "        w_pos = 1.0\n",
    "        w_neg = 1.0\n",
    "    \n",
    "    #create SLIM IP\n",
    "    if not params:\n",
    "        slim_input = {\n",
    "            'X': X,\n",
    "            'X_names': X_names,\n",
    "            'Y': Y,\n",
    "            'C_0': 0.001,\n",
    "            'w_pos': w_pos,\n",
    "            'w_neg': w_neg,\n",
    "            'L0_min': 0,\n",
    "            'L0_max': float('inf'),\n",
    "            'err_min': 0,\n",
    "            'err_max': 1.0,\n",
    "            'pos_err_min': 0,\n",
    "            'pos_err_max': 1.0,\n",
    "            'neg_err_min': 0,\n",
    "            'neg_err_max': 1.0,\n",
    "            'coef_constraints': coef_constraints\n",
    "        }\n",
    "    else:\n",
    "        slim_input = params   \n",
    "    \n",
    "    slim_IP, slim_info = slim.create_slim_IP(slim_input)\n",
    "    \n",
    "    if silent:\n",
    "        slim_IP.set_log_stream(None)\n",
    "        slim_IP.set_error_stream(None)\n",
    "        slim_IP.set_warning_stream(None)\n",
    "        slim_IP.set_results_stream(None)\n",
    "    \n",
    "    # setup SLIM IP parameters\n",
    "    # see docs/usrccplex.pdf for more about these parameters\n",
    "    slim_IP.parameters.timelimit.set(timelimit) #set runtime here\n",
    "    #TODO: add these default settings to create_slim_IP\n",
    "    slim_IP.parameters.randomseed.set(0)\n",
    "    slim_IP.parameters.threads.set(1)\n",
    "    slim_IP.parameters.parallel.set(1)\n",
    "    slim_IP.parameters.output.clonelog.set(0)\n",
    "    slim_IP.parameters.mip.tolerances.mipgap.set(np.finfo(np.float).eps)\n",
    "    slim_IP.parameters.mip.tolerances.absmipgap.set(np.finfo(np.float).eps)\n",
    "    slim_IP.parameters.mip.tolerances.integrality.set(np.finfo(np.float).eps)\n",
    "    slim_IP.parameters.emphasis.mip.set(1)\n",
    "\n",
    "    # solve SLIM IP\n",
    "    slim_IP.solve()\n",
    "\n",
    "    # run quick and dirty tests to make sure that IP output is correct\n",
    "    slim.check_slim_IP_output(slim_IP, slim_info, X, Y, coef_constraints)\n",
    "    \n",
    "    return slim_IP, slim_info\n",
    "        \n",
    "    \n",
    "def train_ebm(X, y, params={}):\n",
    "    \n",
    "    if not params:\n",
    "        n_estimators = 100\n",
    "        learning_rate = 1.0\n",
    "        random_state=0\n",
    "    else:\n",
    "        n_estimators=params['n_estimators']\n",
    "        learning_rate = params['learning_rate']\n",
    "        random_state = params['random_state']\n",
    "        \n",
    "    ebm = ExplainableBoostingClassifier(n_estimators=n_estimators, learning_rate=learning_rate, random_state=random_state).fit(X, y)\n",
    "    return ebm\n",
    "\n",
    "def train_shap(X, y, params={}):\n",
    "\n",
    "    if not params:\n",
    "        gamma = 0.5\n",
    "        n_estimators = 600\n",
    "        objective = 'binary:logistic'\n",
    "        silent=True\n",
    "        nthread=1\n",
    "    else:\n",
    "        gamma = params['gamma']\n",
    "        n_estimators = params['n_estimators']\n",
    "        objective = params['objective']\n",
    "        silent = params['silent']\n",
    "        nthread = params['nthread']\n",
    "        \n",
    "    model = XGBClassifier(max_depth=4,\n",
    "        gamma=gamma,\n",
    "        n_estimators=n_estimators,\n",
    "        objective=objective,\n",
    "        silent=silent,\n",
    "        nthread=nthread)\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "def train_logit(X, y, params={}):\n",
    "    if not params:\n",
    "        penalty='l1'\n",
    "        solver = 'liblinear'\n",
    "        C = 1\n",
    "    else:\n",
    "        penalty = params['penalty']\n",
    "        solver = params['solver']\n",
    "        C = params['C']\n",
    "    logit = LogisticRegression(penalty=penalty, solver=solver, C=C).fit(X, y)\n",
    "    return logit\n",
    "\n",
    "def run_all(X_train, y_train, X_test, y_test, params=None, timelimit=3600, imbalanced=False):\n",
    "    ## runs all three models in consecutive order\n",
    "    \n",
    "    ## SLIM needs specially prepared data\n",
    "    X_train_slim, X_test_slim, y_train_slim, y_test_slim, X_names, y_name = prep_data(X_train, y_train, X_test, y_test)\n",
    "    print('-----------------------------------------')\n",
    "    print(\"Running Supersparse Linear Integer Model\")\n",
    "    print(\"Max runtime: \", timelimit, 'seconds')\n",
    "    slim_model, slim_info = train_slim(X_train_slim, X_names, y_train_slim, y_name, timelimit=timelimit, imbalanced=imbalanced)\n",
    "    slim_results = slim.get_slim_summary(slim_model, slim_info, X_train_slim, y_train_slim)\n",
    "    rho = slim_results['rho']\n",
    "    train_pred = sigmoid(X_train.dot(rho[1:])+rho[0])\n",
    "    test_pred = sigmoid(X_test.dot(rho[1:])+rho[0])\n",
    "    print('train auc: ', auc(y_train, train_pred))\n",
    "    print('test auc: ', auc(y_test, test_pred))\n",
    "    slim_object = (slim_info, slim_results)\n",
    "       \n",
    "    print('-----------------------------------------')\n",
    "    print(\"Running Explainable Boosting Machine\")\n",
    "    ebm = train_ebm(X_train, y_train)\n",
    "    print('train auc: ', auc(y_train, ebm.predict(X_train)))\n",
    "    print('test auc: ', auc(y_test, ebm.predict(X_test)))\n",
    "    \n",
    "    print('-----------------------------------------')\n",
    "    print(\"Running SHAP explained XGBoost\")\n",
    "    shap = train_shap(X_train, y_train)\n",
    "    print('train auc: ', auc(y_train, shap.predict(X_train)))\n",
    "    print('test auc: ', auc(y_test, shap.predict(X_test)))\n",
    "    \n",
    "    print('-----------------------------------------')\n",
    "    print(\"Running Logit\")\n",
    "    logit = train_logit(X_train, y_train)\n",
    "    print('train auc: ', auc(y_train, logit.predict(X_train)))\n",
    "    print('test auc: ', auc(y_test, logit.predict(X_test)))\n",
    "    \n",
    "    return (slim_object, ebm, shap, logit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this cell to change the working directory to access the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\Documents\\StageDaniel\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\Documents\\StageDaniel\\research\n"
     ]
    }
   ],
   "source": [
    "cd research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\danie\\\\Documents\\\\StageDaniel\\\\research'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should be C:\\Users\\danie\\Documents\\StageDaniel\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(results, name ):\n",
    "    with open('results/models/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(results, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "timelimit = 600\n",
    "datasets = ['bankruptcy','breastcancer','haberman','heart','mammo','mushroom','spambase', 'adult']\n",
    "for dataset in datasets:\n",
    "\n",
    "    dataframe = pd.read_csv(os.getcwd() + '/data/'+ dataset + '_processed.csv', sep = ',')\n",
    "    display(dataframe.describe())\n",
    "\n",
    "    # Select X and y from the data and split into train and test set\n",
    "    features = dataframe.columns[1:]\n",
    "    label = dataframe.columns[0]\n",
    "    X = dataframe[features]\n",
    "    X_names = list(X.columns.values)\n",
    "    X_names.insert(0, '(Intercept)')\n",
    "    y = dataframe[label]\n",
    "\n",
    "    KFold_splits = StratifiedKFold(n_splits=5, random_state=0)\n",
    "\n",
    "    for counter, indices in enumerate(KFold_splits.split(X, y)):\n",
    "\n",
    "        X_train, X_test = X.iloc[indices[0]], X.iloc[indices[1]]\n",
    "        y_train, y_test = y.iloc[indices[0]], y.iloc[indices[1]]\n",
    "        results = run_all(X_train, y_train, X_test, y_test, timelimit=timelimit)\n",
    "        del results[0][1]['pretty_model']\n",
    "        save_results(results[:], dataset + '_models_'+str(timelimit)+'_cv'+str(counter))\n",
    "        save_results({'X_train': X_train, 'y_train': y_train, 'X_test': X_test,'y_test': y_test}, dataset + '_data_cv'+str(counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+-------------------+-----------+\n",
      "| PREDICT O IF SCORE >= -3      |                   |           |\n",
      "| ============================= | ================= | ========= |\n",
      "| Married                       |          4 points |   + ..... |\n",
      "| AnyCapitalGains               |          4 points |   + ..... |\n",
      "| Age_22_to_29                  |         -2 points |   + ..... |\n",
      "| ProfVocOrAS                   |         -2 points |   + ..... |\n",
      "| HSDiploma                     |         -4 points |   + ..... |\n",
      "| NoHS                          |         -4 points |   + ..... |\n",
      "| ============================= | ================= | ========= |\n",
      "| ADD POINTS FROM ROWS 1 to 6   |             SCORE |   = ..... |\n",
      "+-------------------------------+-------------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "print(results[:][0][1]['string_model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
